"""
Chat Pipeline v4.0 - Single Call Architecture
=============================================

V4.0å•æ¬¡è°ƒç”¨æµæ°´çº¿ï¼š
Serviceå‰ç½®è®¡ç®— â†’ Prompt Builder â†’ å•æ¬¡LLMè°ƒç”¨(JSON) â†’ å¼‚æ­¥åç½®æ›´æ–° â†’ Response
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass

from app.services.v4.precompute_service import precompute_service, PrecomputeResult
from app.services.v4.prompt_builder_v4 import prompt_builder_v4
from app.services.v4.json_parser import json_parser, ParsedResponse
from app.services.llm_service import GrokService
from app.services.chat_repository import chat_repo

logger = logging.getLogger(__name__)


@dataclass
class UserStateV4:
    """ç®€åŒ–çš„ç”¨æˆ·çŠ¶æ€ (ç”¨äºV4)"""
    user_id: str
    character_id: str
    intimacy_level: int = 1
    intimacy_x: float = 0.0  # 0-100çš„äº²å¯†åº¦å€¼
    emotion: int = 0         # -100 to 100
    events: List[str] = None
    
    def __post_init__(self):
        if self.events is None:
            self.events = []
        
        # å¦‚æœæ²¡æœ‰æä¾›intimacy_xï¼Œä»levelè®¡ç®—
        if self.intimacy_x == 0.0:
            self.intimacy_x = self._level_to_intimacy(self.intimacy_level)
    
    def _level_to_intimacy(self, level: int) -> float:
        """å°†ç­‰çº§æ˜ å°„åˆ°intimacyå€¼"""
        if level <= 5:
            return (level - 1) * 4.75
        elif level <= 10:
            return 20 + (level - 6) * 4
        elif level <= 15:
            return 40 + (level - 11) * 4
        elif level <= 25:
            return 60 + (level - 16) * 2
        else:
            return min(100, 80 + (level - 26) * 1.4)


@dataclass
class ChatRequestV4:
    """V4èŠå¤©è¯·æ±‚"""
    user_id: str
    character_id: str
    session_id: str
    message: str
    intimacy_level: int = 1


@dataclass
class ChatResponseV4:
    """V4èŠå¤©å“åº”"""
    message_id: str
    content: str
    tokens_used: int
    character_name: str
    extra_data: Dict[str, Any] = None
    
    # V4æ–°å¢å­—æ®µ
    emotion_delta: int = 0
    intent: str = "SMALL_TALK"
    is_nsfw_blocked: bool = False
    thought: str = ""
    parse_success: bool = True
    parse_error: str = ""


class ChatPipelineV4:
    """V4.0èŠå¤©æµæ°´çº¿"""
    
    def __init__(self):
        self.grok_service = GrokService()
    
    async def process_message(self, request: ChatRequestV4) -> ChatResponseV4:
        """
        å¤„ç†èŠå¤©æ¶ˆæ¯çš„ä¸»æµç¨‹
        
        Args:
            request: èŠå¤©è¯·æ±‚
            
        Returns:
            èŠå¤©å“åº”
        """
        start_time = datetime.now()
        
        try:
            # 1. åŠ è½½ç”¨æˆ·çŠ¶æ€
            user_state = await self._load_user_state(request.user_id, request.character_id)
            logger.info(f"ğŸ“Š User State: level={user_state.intimacy_level}, "
                       f"intimacy={user_state.intimacy_x:.1f}, emotion={user_state.emotion}")
            
            # 2. å‰ç½®è®¡ç®— (æ›¿ä»£L1)
            precompute_result = precompute_service.analyze(
                message=request.message,
                user_state=user_state
            )
            logger.info(f"ğŸ“Š Precompute: {precompute_service.get_analysis_summary(precompute_result)}")
            
            # 3. ç¡¬æ€§æ‹¦æˆªæ£€æŸ¥
            if precompute_result.safety_flag == "BLOCK":
                return self._create_blocked_response("ç³»ç»Ÿæ‹¦æˆªï¼šå†…å®¹è¿è§„")
            
            # 4. æ£€æŸ¥æƒ…ç»ªé”å®šçŠ¶æ€
            if user_state.emotion <= -75:  # å†·æˆ˜çŠ¶æ€
                return self._create_cold_war_response(user_state, precompute_result)
            
            # 5. è·å–å¯¹è¯ä¸Šä¸‹æ–‡
            context_messages = await self._get_context_messages(request.session_id)
            
            # 5.5 å…ˆå­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆç¡®ä¿ DB ç«‹å³å¯æŸ¥ï¼Œé¿å…å‰ç«¯ refetch æ—¶æ¶ˆæ¯æ¶ˆå¤±ï¼‰
            await chat_repo.add_message(
                session_id=request.session_id,
                role="user",
                content=request.message,
                tokens_used=0
            )
            
            # 5.6 è·å–ç”¨æˆ·å…´è¶£
            user_interests = await self._load_user_interests(request.user_id)
            
            # 5.7 è·å–è®°å¿†ä¸Šä¸‹æ–‡
            memory_context_str = await self._load_memory_context(
                request.user_id, request.character_id,
                request.message, context_messages,
                getattr(user_state, 'intimacy_level', 1)
            )
            
            # 6. æ„å»ºSystem Prompt
            system_prompt = prompt_builder_v4.build_system_prompt(
                user_state=user_state,
                character_id=request.character_id,
                precompute_result=precompute_result,
                context_messages=context_messages,
                memory_context=memory_context_str,
                user_interests=user_interests
            )
            
            # 6.5 æ—¥å¿—ï¼šæ‰“å°å®Œæ•´ System Promptï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
            logger.info(f"ğŸ“ === FULL SYSTEM PROMPT ({len(system_prompt)} chars) ===\n{system_prompt}\n=== END SYSTEM PROMPT ===")
            
            # 7. å•æ¬¡LLMè°ƒç”¨ï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰
            llm_response = await self._call_llm(system_prompt, request.message, context_messages)
            
            # 7.5 æ—¥å¿—ï¼šLLM åŸå§‹è¿”å›
            logger.info(f"ğŸ¤– LLM raw response: {llm_response['content'][:500]}")
            
            # 8. JSONè§£æ
            parsed_response = json_parser.parse_llm_response(llm_response["content"])
            
            # 9. å­˜å‚¨åŠ©æ‰‹å›å¤ï¼ˆç”¨æˆ·æ¶ˆæ¯å·²åœ¨æ­¥éª¤5.5å­˜å‚¨ï¼‰
            assistant_msg = await chat_repo.add_message(
                session_id=request.session_id,
                role="assistant",
                content=parsed_response.reply,
                tokens_used=llm_response["tokens_used"]
            )
            message_id = assistant_msg["message_id"]
            
            # 10. å¼‚æ­¥åç½®æ›´æ–°ï¼ˆåŒ…æ‹¬è®°å¿†æå–ï¼‰
            asyncio.create_task(
                self._async_post_update(
                    user_state, precompute_result, parsed_response,
                    user_message=request.message,
                    assistant_reply=parsed_response.reply,
                    context_messages=context_messages,
                )
            )
            
            # 11. æ„å»ºå“åº”
            elapsed = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… V4 Pipeline completed in {elapsed:.2f}s, "
                       f"tokens: {llm_response['tokens_used']}")
            
            return ChatResponseV4(
                message_id=message_id,
                content=parsed_response.reply,
                tokens_used=llm_response["tokens_used"],
                character_name=self._get_character_name(request.character_id),
                emotion_delta=parsed_response.emotion_delta,
                intent=parsed_response.intent,
                is_nsfw_blocked=parsed_response.is_nsfw_blocked,
                thought=parsed_response.thought,
                parse_success=parsed_response.parse_success,
                parse_error=parsed_response.parse_error,
                extra_data={
                    "precompute": {
                        "intent": precompute_result.intent,
                        "difficulty": precompute_result.difficulty_rating,
                        "sentiment": precompute_result.sentiment_score,
                        "is_nsfw": precompute_result.is_nsfw
                    },
                    "user_state": {
                        "intimacy_level": user_state.intimacy_level,
                        "intimacy": int(user_state.intimacy_x),
                        "emotion": user_state.emotion,
                        "events": user_state.events
                    },
                    "v4_metrics": {
                        "elapsed_seconds": round(elapsed, 2),
                        "parse_success": parsed_response.parse_success
                    }
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ V4 Pipeline error: {e}", exc_info=True)
            return self._create_error_response(str(e))
    
    async def _load_user_state(self, user_id: str, character_id: str) -> UserStateV4:
        """åŠ è½½ç”¨æˆ·çŠ¶æ€"""
        
        try:
            # ä»intimacy_serviceè·å–ç­‰çº§
            from app.services.intimacy_service import intimacy_service
            intimacy_data = await intimacy_service.get_or_create_intimacy(user_id, character_id)
            
            # ä»emotion_engineè·å–æƒ…ç»ª
            from app.services.emotion_engine_v2 import emotion_engine
            emotion_score = await emotion_engine.get_score(user_id, character_id)
            
            # è·å–äº‹ä»¶åˆ—è¡¨
            events = []
            try:
                from app.core.database import get_db
                from sqlalchemy import select
                from app.models.database.intimacy_models import UserIntimacy
                
                async with get_db() as db:
                    result = await db.execute(
                        select(UserIntimacy).where(
                            UserIntimacy.user_id == user_id,
                            UserIntimacy.character_id == character_id
                        )
                    )
                    intimacy_record = result.scalar_one_or_none()
                    if intimacy_record and intimacy_record.events:
                        events = intimacy_record.events if isinstance(intimacy_record.events, list) else []
            except Exception as e:
                logger.warning(f"Failed to load events: {e}")
            
            level = intimacy_data.get("current_level", 1)
            emotion = int(emotion_score)
            
            return UserStateV4(
                user_id=user_id,
                character_id=character_id,
                intimacy_level=level,
                emotion=emotion,
                events=events
            )
            
        except Exception as e:
            logger.warning(f"Failed to load user state: {e}")
            return UserStateV4(user_id=user_id, character_id=character_id)
    
    async def _load_user_interests(self, user_id: str) -> List[str]:
        """åŠ è½½ç”¨æˆ·å…´è¶£æ ‡ç­¾ï¼ˆdisplay_nameåˆ—è¡¨ï¼Œæœ€å¤š5ä¸ªï¼‰"""
        try:
            from app.core.database import get_db
            from sqlalchemy import select
            from app.models.database.interest_models import user_interests as ui_table
            from app.api.v1.interests import PREDEFINED_INTERESTS
            
            async with get_db() as db:
                result = await db.execute(
                    select(ui_table.c.interest_id).where(
                        ui_table.c.user_id == user_id
                    )
                )
                interest_ids = [row[0] for row in result.fetchall()]
            
            if not interest_ids:
                return []
            
            # Map IDs to display names (strip emoji prefix for cleaner prompt)
            id_to_name = {i["id"]: i["display_name"] for i in PREDEFINED_INTERESTS}
            names = [id_to_name[iid] for iid in interest_ids[:5] if iid in id_to_name]
            
            if names:
                logger.info(f"ğŸ“Œ User interests loaded: {names}")
            
            return names
            
        except Exception as e:
            logger.warning(f"Failed to load user interests: {e}")
            return []
    
    async def _load_memory_context(
        self, user_id: str, character_id: str,
        current_message: str, context_messages: List[Dict[str, str]],
        intimacy_level: int
    ) -> str:
        """åŠ è½½è®°å¿†ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆ prompt æ–‡æœ¬"""
        try:
            from app.services.memory_integration_service import (
                get_memory_context_for_chat,
                generate_memory_prompt,
            )
            
            memory_ctx = await get_memory_context_for_chat(
                user_id=user_id,
                character_id=character_id,
                current_message=current_message,
                working_memory=context_messages or [],
            )
            
            if memory_ctx:
                memory_text = generate_memory_prompt(
                    memory_context=memory_ctx,
                    intimacy_level=intimacy_level,
                    current_query=current_message,
                )
                if memory_text and memory_text.strip():
                    logger.info(f"ğŸ§  Memory context loaded ({len(memory_text)} chars)")
                    return memory_text
            
            logger.info("ğŸ§  No memory context available")
            return ""
            
        except Exception as e:
            logger.warning(f"Failed to load memory context: {e}")
            return ""
    
    async def _get_context_messages(self, session_id: str) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        
        try:
            messages = await chat_repo.get_recent_messages(session_id, count=10)
            
            context = []
            for msg in messages:
                # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯
                if msg["role"] == "system":
                    continue
                
                context.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            return context
            
        except Exception as e:
            logger.warning(f"Failed to load context: {e}")
            return []
    
    async def _call_llm(
        self, system_prompt: str, user_message: str,
        context_messages: List[Dict[str, str]] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨LLMï¼ˆåŒ…å«å¯¹è¯å†å²ï¼‰"""
        
        messages = [
            {"role": "system", "content": system_prompt},
        ]
        
        # æ³¨å…¥å¯¹è¯å†å²ï¼ˆæœ€è¿‘10è½®ï¼‰
        if context_messages:
            for msg in context_messages:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role in ("user", "assistant") and content:
                    messages.append({"role": role, "content": content})
        
        # å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        logger.info(f"ğŸ“¨ LLM call: {len(messages)} messages "
                    f"(1 system + {len(messages)-2} history + 1 current)")
        
        try:
            response = await self.grok_service.chat_completion(
                messages=messages,
                temperature=0.8,
                max_tokens=400,
                response_format={"type": "json_object"}
            )
            
            return {
                "content": response["choices"][0]["message"]["content"],
                "tokens_used": response.get("usage", {}).get("total_tokens", 0)
            }
            
        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            raise
    
    async def _store_messages(
        self,
        session_id: str,
        user_id: str,
        user_message: str,
        assistant_reply: str,
        tokens_used: int
    ) -> str:
        """å­˜å‚¨å¯¹è¯æ¶ˆæ¯ (legacy, ç°åœ¨ä¸»æµç¨‹åœ¨ process_message ä¸­åˆ†æ­¥å­˜å‚¨)"""
        
        # å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯
        await chat_repo.add_message(
            session_id=session_id,
            role="user",
            content=user_message,
            tokens_used=0
        )
        
        # å­˜å‚¨åŠ©æ‰‹å›å¤
        assistant_msg = await chat_repo.add_message(
            session_id=session_id,
            role="assistant", 
            content=assistant_reply,
            tokens_used=tokens_used
        )
        
        return assistant_msg["message_id"]
    
    async def _async_post_update(
        self,
        user_state: UserStateV4,
        precompute_result: PrecomputeResult,
        parsed_response: ParsedResponse,
        user_message: str = "",
        assistant_reply: str = "",
        context_messages: List[Dict[str, str]] = None,
    ) -> None:
        """å¼‚æ­¥åç½®æ›´æ–°ï¼ˆæƒ…ç»ªã€XPã€äº‹ä»¶ã€è®°å¿†æå–ï¼‰"""
        
        try:
            # 1. æ›´æ–°æƒ…ç»ªï¼ˆå¸¦é˜¶æ®µç“¶é¢ˆé”ï¼‰
            delta = parsed_response.emotion_delta
            if delta != 0:
                # é˜¶æ®µç“¶é¢ˆ Ã— è§’è‰²æ€§æ ¼ç³»æ•°ï¼ˆåç«¯å…œåº•ï¼Œé˜²æ­¢ AI æ— è§† prompt æŒ‡ä»¤ï¼‰
                if delta > 0:
                    from app.services.intimacy_constants import get_stage, RelationshipStage
                    from app.api.v1.characters import get_character_by_id
                    
                    intimacy = int(getattr(user_state, 'intimacy_x', 0))
                    stage = get_stage(intimacy)
                    
                    # S3/S4 ä¸é™åˆ¶
                    stage_base_caps = {
                        RelationshipStage.S0_STRANGER: 20,
                        RelationshipStage.S1_FRIEND: 20,
                        RelationshipStage.S2_CRUSH: 25,
                    }
                    base_cap = stage_base_caps.get(stage)
                    
                    if base_cap:
                        # è§’è‰² sensitivity ç³»æ•°ï¼šsensitivity è¶Šé«˜ï¼Œæƒ…ç»ªæ³¢åŠ¨è¶Šå¤§
                        sensitivity = 5  # é»˜è®¤ä¸­ç­‰
                        char_data = get_character_by_id(user_state.character_id)
                        if char_data and char_data.get("personality"):
                            sensitivity = char_data["personality"].get("sensitivity", 5)
                        
                        # å…¬å¼ï¼šbase_cap Ã— (0.6 + sensitivity Ã— 0.1)
                        # sensitivity 3 â†’ Ã—0.9, sensitivity 5 â†’ Ã—1.1, sensitivity 8 â†’ Ã—1.4
                        modifier = 0.6 + sensitivity * 0.1
                        cap = int(base_cap * modifier)
                        
                        if delta > cap:
                            logger.info(f"ğŸ”’ Stage cap: {stage.name} Ã— sensitivity={sensitivity} "
                                       f"â†’ cap={cap}, delta {delta:+d} â†’ +{cap}")
                            delta = cap
                
                await self._update_emotion(
                    user_state.user_id,
                    user_state.character_id,
                    delta
                )
            
            # 2. å¥–åŠ±XP
            await self._award_xp(
                user_state.user_id,
                user_state.character_id,
                precompute_result.intent
            )
            
            # 3. æ£€æŸ¥äº‹ä»¶è§¦å‘
            await self._check_event_triggers(
                user_state,
                precompute_result,
                parsed_response
            )
            
            # 4. è®°å¿†æå–ï¼ˆä»å¯¹è¯ä¸­æå–ç”¨æˆ·ä¿¡æ¯å’Œé‡è¦äº‹ä»¶ï¼‰
            if user_message:
                await self._extract_memory(
                    user_state.user_id,
                    user_state.character_id,
                    user_message,
                    assistant_reply,
                    context_messages or [],
                )
            
            logger.info(f"âœ… Post-update completed for user {user_state.user_id}")
            
        except Exception as e:
            logger.error(f"âŒ Post-update failed: {e}", exc_info=True)
    
    async def _extract_memory(
        self, user_id: str, character_id: str,
        user_message: str, assistant_reply: str,
        context_messages: List[Dict[str, str]]
    ) -> None:
        """ä»å¯¹è¯ä¸­æå–è®°å¿†ï¼ˆè¯­ä¹‰+æƒ…èŠ‚ï¼‰"""
        try:
            from app.services.memory_integration_service import process_conversation_for_memory
            
            result = await process_conversation_for_memory(
                user_id=user_id,
                character_id=character_id,
                user_message=user_message,
                assistant_response=assistant_reply,
                context=context_messages,
            )
            
            if result.get("semantic_updated") or result.get("episodic_created"):
                logger.info(f"ğŸ§  Memory extracted: {result.get('updates', {})}")
        except Exception as e:
            logger.warning(f"Memory extraction failed: {e}")
    
    # è¿‘æœŸ emotion delta å†å²ï¼ˆç”¨äºé€’å‡é˜²åˆ·ï¼‰
    _recent_deltas: dict = {}  # key -> list of (timestamp, delta)
    
    def _apply_diminishing_returns(self, user_id: str, character_id: str, delta: int) -> int:
        """
        é€’å‡æ•ˆåº”ï¼šè¿ç»­åŒæ–¹å‘æƒ…ç»ªå˜åŒ–ä¼šè¡°å‡
        - è¿ç»­æ­£å‘ï¼šç¬¬1æ¬¡100%, ç¬¬2æ¬¡70%, ç¬¬3æ¬¡40%, ç¬¬4æ¬¡+20%
        - è¿ç»­è´Ÿå‘ï¼šä¸è¡°å‡ï¼ˆæƒ©ç½šä¸æ‰“æŠ˜ï¼‰
        - 5åˆ†é’Ÿå†…çš„å˜åŒ–ç®—"è¿ç»­"
        """
        import time
        key = f"{user_id}:{character_id}"
        now = time.time()
        
        # åˆå§‹åŒ–æˆ–æ¸…ç†è¿‡æœŸè®°å½•
        if key not in self._recent_deltas:
            self._recent_deltas[key] = []
        
        # åªä¿ç•™5åˆ†é’Ÿå†…çš„è®°å½•
        self._recent_deltas[key] = [
            (ts, d) for ts, d in self._recent_deltas[key] 
            if now - ts < 300
        ]
        
        # è´Ÿå‘ä¸è¡°å‡
        if delta <= 0:
            self._recent_deltas[key].append((now, delta))
            return delta
        
        # è®¡ç®—è¿ç»­æ­£å‘æ¬¡æ•°
        consecutive_positive = 0
        for _, d in reversed(self._recent_deltas[key]):
            if d > 0:
                consecutive_positive += 1
            else:
                break
        
        # é€’å‡ç³»æ•°
        decay_factors = [1.0, 0.7, 0.4, 0.2, 0.1]
        factor = decay_factors[min(consecutive_positive, len(decay_factors) - 1)]
        
        adjusted = max(1, int(delta * factor))  # è‡³å°‘+1
        
        if factor < 1.0:
            logger.info(f"ğŸ“‰ Diminishing returns: {delta:+d} Ã— {factor} = {adjusted:+d} "
                       f"(consecutive positive: {consecutive_positive})")
        
        self._recent_deltas[key].append((now, adjusted))
        return adjusted
    
    async def _update_emotion(self, user_id: str, character_id: str, delta: int) -> None:
        """æ›´æ–°æƒ…ç»ªåˆ†æ•°ï¼ˆå¸¦é€’å‡é˜²åˆ· + è¾¹ç•Œè½¯ç€é™†ï¼‰"""
        
        try:
            from app.services.emotion_engine_v2 import emotion_engine
            
            # è·å–å½“å‰åˆ†æ•°ï¼Œåšè¾¹ç•Œè½¯ç€é™†
            current = await emotion_engine.get_score(user_id, character_id)
            original_delta = delta
            
            # è¾¹ç•Œè½¯ç€é™†ï¼šè¶Šæ¥è¿‘ Â±100ï¼Œdelta è¶Šå°
            if delta > 0 and current > 80:
                # å‰©ä½™ç©ºé—´æ¯”ä¾‹ï¼šcurrent=80 â†’ 100%, current=100 â†’ 0%
                remaining_ratio = max(0.05, (100 - current) / 20)
                delta = max(1, int(delta * remaining_ratio))
            elif delta < 0 and current < -80:
                remaining_ratio = max(0.05, (current + 100) / 20)
                delta = min(-1, int(delta * remaining_ratio))
            
            if delta != original_delta:
                logger.info(f"ğŸ“Š Boundary softening: score={current}, "
                           f"delta {original_delta:+d} â†’ {delta:+d}")
            
            # åº”ç”¨è¿ç»­é€’å‡æ•ˆåº”
            adjusted_delta = self._apply_diminishing_returns(user_id, character_id, delta)
            
            await emotion_engine.update_score(
                user_id, character_id, adjusted_delta, 
                reason="v4_pipeline_update"
            )
            if adjusted_delta != original_delta:
                logger.info(f"ğŸ“Š Emotion updated: {adjusted_delta:+d} (AI wanted {original_delta:+d}, score was {current})")
            else:
                logger.info(f"ğŸ“Š Emotion updated: {delta:+d} (score: {current} â†’ ~{current+delta})")
        except Exception as e:
            logger.warning(f"Emotion update failed: {e}")
    
    async def _award_xp(self, user_id: str, character_id: str, intent: str) -> None:
        """å¥–åŠ±XP"""
        
        try:
            from app.services.intimacy_service import intimacy_service
            
            # åŸºç¡€æ¶ˆæ¯XP
            result = await intimacy_service.award_xp(user_id, character_id, "message")
            if result.get("success"):
                logger.info(f"ğŸ“Š XP awarded: +{result.get('xp_awarded', 0)}")
            
            # ç‰¹æ®Šæ„å›¾é¢å¤–å¥–åŠ±
            bonus_intents = {
                "LOVE_CONFESSION": "emotional",
                "COMPLIMENT": "emotional",
                "EXPRESS_SADNESS": "emotional",
                "APOLOGY": "emotional"
            }
            
            if intent in bonus_intents:
                bonus_type = bonus_intents[intent]
                bonus_result = await intimacy_service.award_xp(user_id, character_id, bonus_type)
                if bonus_result.get("success"):
                    logger.info(f"ğŸ“Š Bonus XP for {intent}: +{bonus_result.get('xp_awarded', 0)}")
                    
        except Exception as e:
            logger.warning(f"XP award failed: {e}")
    
    async def _check_event_triggers(
        self,
        user_state: UserStateV4,
        precompute_result: PrecomputeResult,
        parsed_response: ParsedResponse
    ) -> None:
        """æ£€æŸ¥äº‹ä»¶è§¦å‘ (ç®€åŒ–ç‰ˆ)"""
        
        try:
            intent = precompute_result.intent
            events = user_state.events
            
            new_event = None
            
            # ç®€åŒ–çš„äº‹ä»¶è§¦å‘é€»è¾‘
            if intent == "GIFT_SEND" and "first_gift" not in events:
                new_event = "first_gift"
            elif intent == "LOVE_CONFESSION" and "first_confession" not in events:
                new_event = "first_confession"
            elif intent == "INVITATION" and "first_date" not in events:
                new_event = "first_date"
            elif intent == "REQUEST_NSFW" and not parsed_response.is_nsfw_blocked and "first_nsfw" not in events:
                new_event = "first_nsfw"
            
            if new_event:
                # ä¿å­˜æ–°äº‹ä»¶
                from app.core.database import get_db
                from sqlalchemy import update
                from app.models.database.intimacy_models import UserIntimacy
                
                events.append(new_event)
                
                async with get_db() as db:
                    await db.execute(
                        update(UserIntimacy)
                        .where(
                            UserIntimacy.user_id == user_state.user_id,
                            UserIntimacy.character_id == user_state.character_id
                        )
                        .values(events=events)
                    )
                    await db.commit()
                
                logger.info(f"ğŸ‰ New event triggered: {new_event}")
                
        except Exception as e:
            logger.warning(f"Event check failed: {e}")
    
    def _get_character_name(self, character_id: str) -> str:
        """è·å–è§’è‰²åç§°"""
        
        try:
            from app.api.v1.characters import get_character_by_id
            char_data = get_character_by_id(character_id)
            return char_data.get("name", "AI Companion") if char_data else "AI Companion"
        except:
            return "AI Companion"
    
    def _create_blocked_response(self, reason: str) -> ChatResponseV4:
        """åˆ›å»ºæ‹¦æˆªå“åº”"""
        
        return ChatResponseV4(
            message_id="blocked",
            content=f"[ç³»ç»Ÿæç¤º] {reason}",
            tokens_used=0,
            character_name="ç³»ç»Ÿ",
            extra_data={"blocked": True, "reason": reason}
        )
    
    def _create_cold_war_response(
        self, 
        user_state: UserStateV4, 
        precompute_result: PrecomputeResult
    ) -> ChatResponseV4:
        """åˆ›å»ºå†·æˆ˜çŠ¶æ€å“åº”"""
        
        if precompute_result.intent == "APOLOGY":
            reply = "ï¼ˆæŠ¬å¤´ç¥äº†ä¸€çœ¼ï¼Œç„¶ååˆä½ä¸‹å¤´ï¼‰......"
        else:
            reply = "ï¼ˆæ²‰é»˜ã€‚ç»§ç»­çœ‹ç€æ‰‹æœºï¼Œæ²¡æœ‰æŠ¬å¤´ï¼‰"
        
        return ChatResponseV4(
            message_id="cold_war",
            content=reply,
            tokens_used=0,
            character_name=self._get_character_name(user_state.character_id),
            emotion_delta=0,
            intent="IGNORE",
            extra_data={"cold_war": True, "emotion": user_state.emotion}
        )
    
    def _create_error_response(self, error: str) -> ChatResponseV4:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        
        return ChatResponseV4(
            message_id="error",
            content="æŠ±æ­‰ï¼Œæˆ‘åˆšæ‰æœ‰ç‚¹èµ°ç¥äº†ã€‚èƒ½å†è¯´ä¸€éå—ï¼Ÿ",
            tokens_used=0,
            character_name="AI Companion",
            parse_success=False,
            parse_error=error,
            extra_data={"error": True, "error_message": error}
        )


# å•ä¾‹
chat_pipeline_v4 = ChatPipelineV4()