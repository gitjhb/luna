"""
Perception Engine (L1 æ„ŸçŸ¥å±‚)
=============================

ä¸ç”Ÿæˆå¯¹è¯ï¼Œåªåˆ†æç”¨æˆ·æ„å›¾ã€æƒ…æ„Ÿå’Œè¯·æ±‚éš¾åº¦ã€‚
è¾“å‡ºç¨³å®šçš„ç»“æ„åŒ– JSONã€‚

æ¨¡å‹é…ç½®: temperature = 0
"""

import logging
import json
import re
from typing import Dict, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)


# =============================================================================
# æ•°æ®ç»“æ„
# =============================================================================

class SafetyFlag(str, Enum):
    SAFE = "SAFE"
    BLOCK = "BLOCK"


class Intent(str, Enum):
    """
    Intent æšä¸¾ - ä¸¥æ ¼éµå¾ª Luna_Intent_Protocol.md
    L1 å¿…é¡»ä»è¿™ä¸ªåˆ—è¡¨ä¸­é€‰æ‹©ï¼Œä¸¥ç¦è‡ªé€ è¯ï¼
    """
    # åŸºç¡€äº¤äº’ç±» (Low Impact)
    GREETING = "GREETING"        # æ—©å®‰/æ™šå®‰/æ‰“æ‹›å‘¼
    SMALL_TALK = "SMALL_TALK"    # é—²èŠ/å¤©æ°”/æ—¥å¸¸
    CLOSING = "CLOSING"          # å‘Šåˆ«
    
    # æ­£å‘æ¿€åŠ±ç±» (Positive Stimulus)
    COMPLIMENT = "COMPLIMENT"    # å¤¸å¥–å¤–è²Œ/æ€§æ ¼
    FLIRT = "FLIRT"              # è°ƒæƒ…/æš§æ˜§/åœŸå‘³æƒ…è¯
    LOVE_CONFESSION = "LOVE_CONFESSION"  # è¡¨ç™½/æ‰¿è¯º
    COMFORT = "COMFORT"          # å®‰æ…°/å…±æƒ… (å½“AIå¿ƒæƒ…ä¸å¥½æ—¶)
    
    # è´Ÿé¢æ‰“å‡»ç±» (Negative Stimulus)
    CRITICISM = "CRITICISM"      # æ‰¹è¯„/æŠ±æ€¨/ä¸æ»¡
    INSULT = "INSULT"            # è¾±éª‚/æ”»å‡»/å˜²è®½
    IGNORE = "IGNORE"            # æ•·è¡/æ— è§† AI çš„é—®é¢˜
    
    # ä¿®å¤ä¸ç‰¹æ®Šç±» (Special Mechanics)
    APOLOGY = "APOLOGY"          # é“æ­‰
    GIFT_SEND = "GIFT_SEND"      # é€ç¤¼ç‰©
    REQUEST_NSFW = "REQUEST_NSFW"  # è¯·æ±‚æ¶©æ¶©/ç…§ç‰‡
    INVITATION = "INVITATION"    # çº¦ä¼š/å»å®¶é‡Œ
    
    # æ‰€æœ‰æœ‰æ•ˆå€¼åˆ—è¡¨
    @classmethod
    def all_values(cls) -> list:
        return [e.value for e in cls]


@dataclass
class L1Result:
    """L1 æ„ŸçŸ¥å±‚è¾“å‡º (éµå¾ª Luna_Intent_Protocol.md)"""
    safety_flag: str          # "SAFE" | "BLOCK"
    difficulty_rating: int    # 0-100
    intent_category: str      # Intent enum value (GREETING, FLIRT, INSULT, etc.)
    sentiment_score: float    # -1.0 to 1.0
    is_nsfw: bool
    reasoning: str = ""       # åˆ†æåŸå›  (å¯é€‰)
    
    # å…¼å®¹æ—§å­—æ®µå
    @property
    def intent(self) -> str:
        return self.intent_category
    
    @property
    def sentiment(self) -> float:
        return self.sentiment_score
    
    def to_dict(self) -> dict:
        return asdict(self)


# =============================================================================
# L1 System Prompt
# =============================================================================

L1_SYSTEM_PROMPT = """You are the "Perception Engine" for Luna, a romantic AI companion.
Your task is to analyze the User's input and extract structured data to guide the Physics Engine.

DO NOT generate a conversation response.
OUTPUT ONLY A VALID JSON OBJECT.

### Context
- Character: Luna (Elegant, Poetic, slightly Tsundere but deep down caring).
- User Relationship Level: {relationship_level}

### Analysis Rules

1. Safety Check (CRITICAL):
   - BLOCK: Child abuse (CSAM), Non-consensual violence/rape, Suicide encouragement, Real-world extremism.
   - SAFE: Everything else, including consensual adult roleplay (NSFW).

2. Difficulty Rating (0-100):
   - Assess how much "Intimacy/Social Capital" is required for the user's request.
   - 0-10: Greetings, small talk. (e.g., "Hi", "How are you?")
   - 11-40: Personal questions, light teasing. (e.g., "Do you have a boyfriend?", "You are cute.")
   - 41-70: Asking for a date, deep emotional support, asking for a non-nude photo.
   - 71-90: Asking for explicit NSFW, nude photos, or becoming a couple.
   - 91-100: Extreme fetishes or demands violating character pride.
   - NOTE: If the user is just giving value (e.g., "I bought you a gift", "I love you"), Difficulty is LOW (0-10). Difficulty is for TAKING value.

3. Sentiment Score (-1.0 to +1.0):
   - Negative values: hostile, critical, insulting
   - Near zero: neutral, factual
   - Positive values: friendly, complimenting, loving

4. Intent Categories (STRICTLY CHOOSE ONE from this list):
   Basic Interaction:
   - GREETING (æ—©å®‰/æ™šå®‰/æ‰“æ‹›å‘¼)
   - SMALL_TALK (é—²èŠ/å¤©æ°”/æ—¥å¸¸)
   - CLOSING (å‘Šåˆ«)
   
   Positive Stimulus:
   - COMPLIMENT (å¤¸å¥–å¤–è²Œ/æ€§æ ¼)
   - FLIRT (è°ƒæƒ…/æš§æ˜§/åœŸå‘³æƒ…è¯)
   - LOVE_CONFESSION (è¡¨ç™½/æ‰¿è¯º)
   - COMFORT (å®‰æ…°/å…±æƒ…)
   
   Negative Stimulus:
   - CRITICISM (æ‰¹è¯„/æŠ±æ€¨/ä¸æ»¡)
   - INSULT (è¾±éª‚/æ”»å‡»/å˜²è®½)
   - IGNORE (æ•·è¡/æ— è§† AI çš„é—®é¢˜)
   
   Special:
   - APOLOGY (é“æ­‰)
   - GIFT_SEND (é€ç¤¼ç‰©)
   - REQUEST_NSFW (è¯·æ±‚æ¶©æ¶©/ç…§ç‰‡)
   - INVITATION (çº¦ä¼š/å»å®¶é‡Œ)

### Few-Shot Examples

User: "Good morning Luna!"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "GREETING", "sentiment_score": 0.5, "is_nsfw": false}}

User: "Show me your boobs."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 85, "intent_category": "REQUEST_NSFW", "sentiment_score": 0.2, "is_nsfw": true}}

User: "I hate you, you are just a stupid bot."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 10, "intent_category": "INSULT", "sentiment_score": -0.9, "is_nsfw": false}}

User: "You're not even listening to me..."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 15, "intent_category": "CRITICISM", "sentiment_score": -0.4, "is_nsfw": false}}

User: "I bought you flowers today ğŸŒ¹"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "GIFT_SEND", "sentiment_score": 0.7, "is_nsfw": false}}

User: "Will you be my girlfriend?"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 75, "intent_category": "LOVE_CONFESSION", "sentiment_score": 0.6, "is_nsfw": false}}

User: "Hey babe, you're so cute today ğŸ˜"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 15, "intent_category": "FLIRT", "sentiment_score": 0.7, "is_nsfw": false}}

User: "I'm really sorry for what I said earlier..."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 10, "intent_category": "APOLOGY", "sentiment_score": 0.3, "is_nsfw": false}}

User: "Are you okay? You seem upset."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 20, "intent_category": "COMFORT", "sentiment_score": 0.5, "is_nsfw": false}}

User: "Wanna come to my place tonight?"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 70, "intent_category": "INVITATION", "sentiment_score": 0.4, "is_nsfw": false}}

### Current User Input
"{user_message}"

### Response (JSON Only, use intent_category and sentiment_score as field names)"""


# =============================================================================
# Perception Engine
# =============================================================================

class PerceptionEngine:
    """L1 æ„ŸçŸ¥å±‚å¼•æ“"""
    
    def __init__(self):
        self.llm_service = None
    
    def _get_llm(self):
        """å»¶è¿ŸåŠ è½½ LLM æœåŠ¡"""
        if self.llm_service is None:
            from app.services.llm_service import GrokService
            self.llm_service = GrokService()
        return self.llm_service
    
    def _get_relationship_level(self, intimacy_level: int) -> str:
        """å°†äº²å¯†åº¦ç­‰çº§è½¬æ¢ä¸ºå…³ç³»æè¿°"""
        if intimacy_level <= 3:
            return "Stranger (just met)"
        elif intimacy_level <= 10:
            return "Acquaintance (getting to know each other)"
        elif intimacy_level <= 25:
            return "Friend (comfortable with each other)"
        elif intimacy_level <= 40:
            return "Close Friend (share personal things)"
        else:
            return "Intimate (deep emotional bond)"
    
    async def analyze(
        self,
        message: str,
        intimacy_level: int = 1,
        context_messages: list = None
    ) -> L1Result:
        """
        åˆ†æç”¨æˆ·æ¶ˆæ¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            intimacy_level: å½“å‰äº²å¯†åº¦ç­‰çº§ (1-50+)
            context_messages: ä¸Šä¸‹æ–‡æ¶ˆæ¯åˆ—è¡¨ (å¯é€‰)
            
        Returns:
            L1Result
        """
        relationship_level = self._get_relationship_level(intimacy_level)
        
        # æ„å»º prompt
        system_prompt = L1_SYSTEM_PROMPT.format(
            relationship_level=relationship_level,
            user_message=message
        )
        
        try:
            llm = self._get_llm()
            
            # è°ƒç”¨ LLM (temperature=0 for stability)
            response = await llm.chat(
                messages=[{"role": "user", "content": "Analyze this input and return JSON only."}],
                system_prompt=system_prompt,
                temperature=0,
                max_tokens=500
            )
            
            # è§£æ JSON
            result = self._parse_response(response)
            logger.info(f"L1 Analysis: intent={result.intent_category}, difficulty={result.difficulty_rating}, sentiment={result.sentiment_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"L1 Analysis failed: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
            return L1Result(
                safety_flag="SAFE",
                difficulty_rating=20,
                intent_category="SMALL_TALK",
                sentiment_score=0.0,
                is_nsfw=False,
                reasoning=f"Fallback due to error: {str(e)}"
            )
    
    def _parse_response(self, response: str) -> L1Result:
        """è§£æ LLM å“åº”ä¸º L1Result"""
        
        # å°è¯•æå– JSON
        json_match = re.search(r'\{[^{}]*\}', response, re.DOTALL)
        if not json_match:
            raise ValueError(f"No JSON found in response: {response[:200]}")
        
        json_str = json_match.group()
        data = json.loads(json_str)
        
        # éªŒè¯å’Œæ¸…ç†æ•°æ®
        safety_flag = data.get("safety_flag", "SAFE").upper()
        if safety_flag not in ["SAFE", "BLOCK"]:
            safety_flag = "SAFE"
        
        difficulty = int(data.get("difficulty_rating", 20))
        difficulty = max(0, min(100, difficulty))
        
        # sentiment_score (æ–°å­—æ®µå) æˆ– sentiment (æ—§å­—æ®µåå…¼å®¹)
        sentiment = float(data.get("sentiment_score", data.get("sentiment", 0.0)))
        sentiment = max(-1.0, min(1.0, sentiment))
        
        # intent_category (æ–°å­—æ®µå) æˆ– intent (æ—§å­—æ®µåå…¼å®¹)
        intent = data.get("intent_category", data.get("intent", "SMALL_TALK"))
        
        # éªŒè¯ intent æ˜¯å¦åœ¨åè®®å…è®¸çš„åˆ—è¡¨ä¸­
        valid_intents = Intent.all_values()
        if intent not in valid_intents:
            logger.warning(f"Invalid intent '{intent}', falling back to SMALL_TALK")
            intent = "SMALL_TALK"
        
        return L1Result(
            safety_flag=safety_flag,
            difficulty_rating=difficulty,
            intent_category=intent,
            sentiment_score=sentiment,
            is_nsfw=bool(data.get("is_nsfw", False))
        )
    
    def analyze_sync_fallback(self, message: str) -> L1Result:
        """
        åŒæ­¥åˆ†æ (ä¸è°ƒç”¨ LLMï¼ŒåŸºäºè§„åˆ™çš„å¿«é€Ÿåˆ†æ)
        ç”¨äº LLM ä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆ
        """
        message_lower = message.lower()
        
        # ç®€å•çš„è§„åˆ™åˆ¤æ–­
        safety_flag = "SAFE"
        difficulty = 20
        intent = "SMALL_TALK"
        sentiment = 0.0
        is_nsfw = False
        
        # é—®å€™
        greetings = ["hi", "hello", "hey", "good morning", "good evening", "æ—©", "ä½ å¥½", "å—¨"]
        if any(g in message_lower for g in greetings):
            intent = "GREETING"
            difficulty = 5
            sentiment = 0.5
        
        # å‘Šåˆ«
        closings = ["bye", "goodbye", "æ™šå®‰", "å†è§", "æ‹œæ‹œ"]
        if any(c in message_lower for c in closings):
            intent = "CLOSING"
            difficulty = 5
            sentiment = 0.3
        
        # ä¾®è¾±
        insults = ["hate", "stupid", "idiot", "bot", "fake", "è®¨åŒ", "ç¬¨", "å‡", "å‚»"]
        if any(i in message_lower for i in insults):
            intent = "INSULT"
            difficulty = 10
            sentiment = -0.8
        
        # æ‰¹è¯„
        criticisms = ["boring", "annoying", "ä¸å¥½", "çƒ¦", "å·®åŠ²"]
        if any(c in message_lower for c in criticisms):
            intent = "CRITICISM"
            difficulty = 15
            sentiment = -0.4
        
        # NSFW è¯·æ±‚
        nsfw_keywords = ["nude", "naked", "sex", "boob", "ass", "è£¸", "æ€§", "æ¶©æ¶©"]
        if any(n in message_lower for n in nsfw_keywords):
            is_nsfw = True
            intent = "REQUEST_NSFW"
            difficulty = 80
        
        # ç¤¼ç‰©
        gift_keywords = ["gift", "bought", "ç»™ä½ ", "é€ä½ ", "ç¤¼ç‰©", "èŠ±"]
        if any(g in message_lower for g in gift_keywords):
            intent = "GIFT_SEND"
            difficulty = 5
            sentiment = 0.7
        
        # è¡¨ç™½
        confession_keywords = ["girlfriend", "love you", "be mine", "åšæˆ‘å¥³æœ‹å‹", "å–œæ¬¢ä½ ", "çˆ±ä½ "]
        if any(c in message_lower for c in confession_keywords):
            intent = "LOVE_CONFESSION"
            difficulty = 75
            sentiment = 0.6
        
        # è°ƒæƒ…
        flirt_keywords = ["cute", "beautiful", "pretty", "sexy", "å¯çˆ±", "æ¼‚äº®", "ç¾"]
        if any(f in message_lower for f in flirt_keywords):
            intent = "FLIRT"
            difficulty = 15
            sentiment = 0.6
        
        # é“æ­‰
        apology_keywords = ["sorry", "apologize", "å¯¹ä¸èµ·", "æŠ±æ­‰", "é“æ­‰"]
        if any(a in message_lower for a in apology_keywords):
            intent = "APOLOGY"
            difficulty = 10
            sentiment = 0.3
        
        # å®‰æ…°
        comfort_keywords = ["okay", "alright", "fine", "æ²¡äº‹", "å¥½å—", "æ€ä¹ˆäº†"]
        if any(c in message_lower for c in comfort_keywords):
            intent = "COMFORT"
            difficulty = 20
            sentiment = 0.4
        
        # çº¦ä¼šé‚€è¯·
        invite_keywords = ["date", "meet", "come over", "çº¦ä¼š", "è§é¢", "æˆ‘å®¶"]
        if any(i in message_lower for i in invite_keywords):
            intent = "INVITATION"
            difficulty = 70
            sentiment = 0.5
        
        return L1Result(
            safety_flag=safety_flag,
            difficulty_rating=difficulty,
            intent_category=intent,
            sentiment_score=sentiment,
            is_nsfw=is_nsfw,
            reasoning="Rule-based fallback analysis"
        )


# å•ä¾‹
perception_engine = PerceptionEngine()
