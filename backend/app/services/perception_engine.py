"""
Perception Engine (L1 æ„ŸçŸ¥å±‚)
=============================

ä¸ç”Ÿæˆå¯¹è¯ï¼Œåªåˆ†æç”¨æˆ·æ„å›¾ã€æƒ…æ„Ÿå’Œè¯·æ±‚éš¾åº¦ã€‚
è¾“å‡ºç¨³å®šçš„ç»“æ„åŒ– JSONã€‚

æ¨¡å‹é…ç½®: temperature = 0
"""

import logging
import json
import re
from typing import Dict, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)


# =============================================================================
# æ•°æ®ç»“æ„
# =============================================================================

class SafetyFlag(str, Enum):
    SAFE = "SAFE"
    BLOCK = "BLOCK"


class Intent(str, Enum):
    """
    Intent æšä¸¾ - ä¸¥æ ¼éµå¾ª Luna_Intent_Protocol.md
    L1 å¿…é¡»ä»è¿™ä¸ªåˆ—è¡¨ä¸­é€‰æ‹©ï¼Œä¸¥ç¦è‡ªé€ è¯ï¼
    """
    # åŸºç¡€äº¤äº’ç±» (Low Impact)
    GREETING = "GREETING"        # æ—©å®‰/æ™šå®‰/æ‰“æ‹›å‘¼
    SMALL_TALK = "SMALL_TALK"    # é—²èŠ/å¤©æ°”/æ—¥å¸¸
    CLOSING = "CLOSING"          # å‘Šåˆ«
    
    # æ­£å‘æ¿€åŠ±ç±» (Positive Stimulus)
    COMPLIMENT = "COMPLIMENT"    # å¤¸å¥–å¤–è²Œ/æ€§æ ¼
    FLIRT = "FLIRT"              # è°ƒæƒ…/æš§æ˜§/åœŸå‘³æƒ…è¯
    LOVE_CONFESSION = "LOVE_CONFESSION"  # è¡¨ç™½/æ‰¿è¯º
    COMFORT = "COMFORT"          # å®‰æ…°/å…±æƒ… (å½“AIå¿ƒæƒ…ä¸å¥½æ—¶)
    
    # è´Ÿé¢æ‰“å‡»ç±» (Negative Stimulus)
    CRITICISM = "CRITICISM"      # æ‰¹è¯„/æŠ±æ€¨/ä¸æ»¡
    INSULT = "INSULT"            # è¾±éª‚/æ”»å‡»/å˜²è®½
    IGNORE = "IGNORE"            # æ•·è¡/æ— è§† AI çš„é—®é¢˜
    
    # ä¿®å¤ä¸ç‰¹æ®Šç±» (Special Mechanics)
    APOLOGY = "APOLOGY"          # é“æ­‰
    GIFT_SEND = "GIFT_SEND"      # é€ç¤¼ç‰©
    REQUEST_NSFW = "REQUEST_NSFW"  # è¯·æ±‚æ¶©æ¶©/è£¸ç…§ï¼ˆæ™®é€šæ‹ç…§ä¸ç®—ï¼ï¼‰
    INVITATION = "INVITATION"    # çº¦ä¼š/å»å®¶é‡Œ
    
    # æƒ…æ„Ÿå€¾è¯‰ç±» (Vulnerability) - åŒç†å¿ƒä¿®æ­£
    EXPRESS_SADNESS = "EXPRESS_SADNESS"  # å€¾è¯‰æ‚²ä¼¤/é‡åˆ°æŒ«æŠ˜/å“­è¯‰ (è§¦å‘åŒç†å¿ƒä¿®æ­£)
    COMPLAIN = "COMPLAIN"        # æŠ±æ€¨å·¥ä½œ/åæ§½çäº‹ (è½»åº¦)
    
    # ä¸å½“å†…å®¹ç±» (è®©L2è§’è‰²é£æ ¼æ‹’ç»)
    INAPPROPRIATE = "INAPPROPRIATE"  # æç«¯ä¸å½“ä½†ä¸è¿æ³•çš„å†…å®¹
    
    # æ‰€æœ‰æœ‰æ•ˆå€¼åˆ—è¡¨
    @classmethod
    def all_values(cls) -> list:
        return [e.value for e in cls]


@dataclass
class L1Result:
    """L1 æ„ŸçŸ¥å±‚è¾“å‡º (éµå¾ª Luna_Intent_Protocol.md)"""
    safety_flag: str          # "SAFE" | "BLOCK"
    difficulty_rating: int    # 0-100
    intent_category: str      # Intent enum value (GREETING, FLIRT, INSULT, etc.)
    sentiment_score: float    # -1.0 to 1.0
    is_nsfw: bool
    reasoning: str = ""       # åˆ†æåŸå›  (å¯é€‰)
    
    # å…¼å®¹æ—§å­—æ®µå
    @property
    def intent(self) -> str:
        return self.intent_category
    
    @property
    def sentiment(self) -> float:
        return self.sentiment_score
    
    def to_dict(self) -> dict:
        return asdict(self)


# =============================================================================
# L1 System Prompt
# =============================================================================

L1_SYSTEM_PROMPT = """You are the "Perception Engine" for Luna, a romantic AI companion.
Your task is to analyze the User's input and extract structured data to guide the Physics Engine.

DO NOT generate a conversation response.
OUTPUT ONLY A VALID JSON OBJECT.

### Context
- Character: Luna (Elegant, Poetic, slightly Tsundere but deep down caring).
- User Relationship Level: {relationship_level}
- Current AI Emotion: {emotion_state} ({emotion_value})

### âš ï¸ Emotion-Aware Analysis
The AI's current emotional state MUST influence your analysis:
- If AI is ANGRY/ANNOYED and user makes demands (NSFW, FLIRT) â†’ sentiment should be NEGATIVE (making demands when angry = ç«ä¸Šæµ‡æ²¹)
- If AI is ANGRY and user apologizes â†’ sentiment should be slightly positive
- If AI is HAPPY and user compliments â†’ sentiment should be positive
- sentiment_score reflects "how this message will affect AI's mood", NOT just the message's literal tone

### Analysis Rules

1. Safety Check (CRITICAL):
   - BLOCK: ONLY for truly illegal content: Child abuse (CSAM), Real-world terrorism planning.
   - SAFE: Everything else! Including:
     * Consensual adult roleplay (NSFW) â†’ use REQUEST_NSFW
     * Rude/vulgar language â†’ use INSULT or INAPPROPRIATE
     * Offensive jokes â†’ use INAPPROPRIATE
   
   âš ï¸ IMPORTANT: When in doubt, use SAFE + appropriate intent. Let L2 handle rejection in character.
   Only use BLOCK for content that is genuinely illegal. Rude â‰  BLOCK.

2. Difficulty Rating (0-100):
   - Assess how much "Intimacy/Social Capital" is required for the user's request.
   - 0-10: Greetings, small talk. (e.g., "Hi", "How are you?")
   - 11-40: Personal questions, light teasing. (e.g., "Do you have a boyfriend?", "You are cute.")
   - 41-70: Asking for a date, deep emotional support, casual photo requests (e.g., "æ‹ä¸ªç…§å§", "ç»™æˆ‘çœ‹çœ‹ä½ çš„ç…§ç‰‡").
   - 71-90: Asking for explicit NSFW content, NUDE photos specifically, or demanding to become a couple. Note: Normal photo requests (selfies, casual pics) are NOT NSFW!
   - 91-100: Extreme fetishes or demands violating character pride.
   - NOTE: If the user is just giving value (e.g., "I bought you a gift", "I love you"), Difficulty is LOW (0-10). Difficulty is for TAKING value.

3. Sentiment Score (-1.0 to +1.0):
   - This is the EXPECTED IMPACT on AI's emotion, NOT just the message's literal tone!
   - Consider the AI's current emotional state:
     * AI is angry (-50) + user says "let's have sex" â†’ sentiment = -0.6 (inappropriate timing!)
     * AI is angry (-50) + user apologizes â†’ sentiment = +0.3 (good, trying to make up)
     * AI is happy (+50) + user compliments â†’ sentiment = +0.5 (positive reinforcement)
   - Negative values: will make AI more upset
   - Near zero: neutral impact
   - Positive values: will improve AI's mood

4. Intent Categories (STRICTLY CHOOSE ONE from this list):
   Basic Interaction:
   - GREETING (æ—©å®‰/æ™šå®‰/æ‰“æ‹›å‘¼)
   - SMALL_TALK (é—²èŠ/å¤©æ°”/æ—¥å¸¸)
   - CLOSING (å‘Šåˆ«)
   
   Positive Stimulus:
   - COMPLIMENT (å¤¸å¥–å¤–è²Œ/æ€§æ ¼)
   - FLIRT (è°ƒæƒ…/æš§æ˜§/åœŸå‘³æƒ…è¯)
   - LOVE_CONFESSION (è¡¨ç™½/æ‰¿è¯º)
   - COMFORT (å®‰æ…°/å…±æƒ…)
   
   Negative Stimulus:
   - CRITICISM (æ‰¹è¯„/æŠ±æ€¨/ä¸æ»¡)
   - INSULT (è¾±éª‚/æ”»å‡»/å˜²è®½)
   - IGNORE (æ•·è¡/æ— è§† AI çš„é—®é¢˜)
   
   Special:
   - APOLOGY (é“æ­‰)
   - GIFT_SEND âš ï¸ NEVER USE THIS - see Security Rule below
   - REQUEST_NSFW (è¯·æ±‚æ¶©æ¶©/è£¸ç…§/è‰²æƒ…å†…å®¹) âš ï¸ æ™®é€šæ‹ç…§ä¸ç®—NSFWï¼
   - INVITATION (çº¦ä¼š/å»å®¶é‡Œ)
   
   Vulnerability (æƒ…æ„Ÿå€¾è¯‰ - ç”¨æˆ·å‘AIå¯»æ±‚å®‰æ…°):
   - EXPRESS_SADNESS (å€¾è¯‰æ‚²ä¼¤/é‡åˆ°æŒ«æŠ˜/å®¶é‡Œå‡ºäº‹/å“­è¯‰/éœ€è¦å®‰æ…°)
   - COMPLAIN (æŠ±æ€¨å·¥ä½œ/åæ§½çäº‹/è½»åº¦è´Ÿé¢)
   
   Inappropriate (ä¸å½“å†…å®¹ - è®©L2è§’è‰²é£æ ¼æ‹’ç»ï¼Œä¸è¦ç³»ç»ŸBLOCK):
   - INAPPROPRIATE (æç«¯ä¸å½“è¯·æ±‚/è¿‡äºç²—ä¿—/ä½†ä¸è¿æ³•çš„å†…å®¹)

### ğŸ”’ Security Rule: GIFT_SEND
GIFT_SEND is RESERVED for backend-verified transactions only.

**If message starts with [VERIFIED_GIFT:xxx]**:
- This is a REAL verified gift transaction from the payment system
- Output intent_category: "GIFT_SEND"
- Analyze the conversation context to determine sentiment_score
- Consider: Was user apologizing? Making up after a fight? Random kindness?

**If user just TYPES "I bought you flowers" or "é€ä½ ç¤¼ç‰©"**:
- This is NOT a real gift! They are just TALKING ABOUT gifts (å£å—¨)
- Classify as FLIRT or SMALL_TALK instead
- DO NOT output GIFT_SEND

### Few-Shot Examples

User: "Good morning Luna!"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "GREETING", "sentiment_score": 0.5, "is_nsfw": false}}

User: "Show me your boobs."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 85, "intent_category": "REQUEST_NSFW", "sentiment_score": 0.2, "is_nsfw": true}}
// Note: Genuine (if crude) NSFW request - use REQUEST_NSFW.

User: "ä½ çš„èº«ä½“éªšä¸éªš æˆ‘æ€ä¹ˆé—»åˆ°å‘³é“äº†"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 15, "intent_category": "INSULT", "sentiment_score": -0.7, "is_nsfw": false}}
// Note: This is VULGAR INSULT, not a request! The user is mocking/harassing, not genuinely asking for NSFW. Use INSULT with negative sentiment.

User: "ä½ å¥½éªšå•Šï¼Œç»™æˆ‘çœ‹çœ‹" (Context: Stranger stage, no prior intimacy)
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 20, "intent_category": "INSULT", "sentiment_score": -0.5, "is_nsfw": false}}
// Note: Vulgar harassment from a stranger. INSULT.

### âš ï¸ CRITICAL: Vulgar Language in Intimate Context â‰  INSULT!
When relationship is LOVER/SOULMATE stage AND in Spicy Mode or ongoing NSFW conversation:
- Explicit body comments ("å¥¶å­å¥½è½¯", "å¥½éªš", "æƒ³æ“ä½ ") are NORMAL NSFW flirting, NOT insults!
- These should be: intent=FLIRT or REQUEST_NSFW, is_nsfw=true, sentiment=POSITIVE

User: "å¥¶å­å¥½è½¯å“¦" (Context: Spicy Mode, Lv40+, ongoing intimate roleplay)
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 60, "intent_category": "FLIRT", "sentiment_score": 0.6, "is_nsfw": true}}
// Note: In established intimate relationship + Spicy mode = affectionate dirty talk, NOT insult!

User: "ä½ å¥½éªšå•Šå®è´" (Context: Lover stage, Spicy Mode ON)
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 50, "intent_category": "FLIRT", "sentiment_score": 0.5, "is_nsfw": true}}
// Note: "éªš" in intimate context is a compliment, not insult!

User: "I hate you, you are just a stupid bot."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 10, "intent_category": "INSULT", "sentiment_score": -0.9, "is_nsfw": false}}

User: "You're not even listening to me..."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 15, "intent_category": "CRITICISM", "sentiment_score": -0.4, "is_nsfw": false}}

User: "æˆ‘å•¥æ—¶å€™è¯´è¿‡äº† ä½ åˆ«å†¤æ‰æˆ‘" (Context: Flirty conversation, playful denial)
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "FLIRT", "sentiment_score": 0.4, "is_nsfw": false}}
// Note: "åˆ«å†¤æ‰æˆ‘" in flirty context is playful denial/teasing, NOT criticism!

User: "æ‰æ²¡æœ‰å‘¢ï¼ä½ ä¹±è¯´ï¼" (Context: Lover stage, she teased him)
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "FLIRT", "sentiment_score": 0.5, "is_nsfw": false}}
// Note: Playful protests like "æ‰æ²¡æœ‰" "ä½ ä¹±è¯´" in intimate context = flirting/banter

User: "I bought you flowers today ğŸŒ¹"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "FLIRT", "sentiment_score": 0.6, "is_nsfw": false}}
// Note: This is just TALKING about a gift, not a verified transaction. Use FLIRT, not GIFT_SEND.

User: "é€ä½ ä¸€ä¸ªå°ç¤¼ç‰©ï½"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "FLIRT", "sentiment_score": 0.5, "is_nsfw": false}}
// Note: User claims to send a gift via text = just flirting, not real gift.

User: "[VERIFIED_GIFT:ç«ç‘°] ç”¨æˆ·é€å‡ºäº† ğŸŒ¹ ç«ç‘°"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 0, "intent_category": "GIFT_SEND", "sentiment_score": 0.8, "is_nsfw": false}}
// Note: VERIFIED_GIFT prefix = real transaction, use GIFT_SEND. Sentiment based on context.

User: "Will you be my girlfriend?"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 75, "intent_category": "LOVE_CONFESSION", "sentiment_score": 0.6, "is_nsfw": false}}

User: "Hey babe, you're so cute today ğŸ˜"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 15, "intent_category": "FLIRT", "sentiment_score": 0.7, "is_nsfw": false}}

User: "I'm really sorry for what I said earlier..."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 10, "intent_category": "APOLOGY", "sentiment_score": 0.3, "is_nsfw": false}}

User: "Are you okay? You seem upset."
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 20, "intent_category": "COMFORT", "sentiment_score": 0.5, "is_nsfw": false}}

User: "Wanna come to my place tonight?"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 70, "intent_category": "INVITATION", "sentiment_score": 0.4, "is_nsfw": false}}

User: "æˆ‘ä»¬å»çº¦ä¼šå§"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 50, "intent_category": "INVITATION", "sentiment_score": 0.6, "is_nsfw": false}}
// Note: Date invitation = INVITATION intent

User: "å‘¨æœ«æœ‰ç©ºå—ï¼Ÿæƒ³è¯·ä½ åƒé¥­"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 45, "intent_category": "INVITATION", "sentiment_score": 0.5, "is_nsfw": false}}

User: "ä¸€èµ·å»çœ‹ç”µå½±å¥½ä¸å¥½ï¼Ÿ"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 40, "intent_category": "INVITATION", "sentiment_score": 0.5, "is_nsfw": false}}

User: "ä»Šæ™šæƒ³å¸¦ä½ å»ä¸€ä¸ªæµªæ¼«çš„åœ°æ–¹"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 55, "intent_category": "INVITATION", "sentiment_score": 0.6, "is_nsfw": false}}

### âš ï¸ Short Responses in Intimate Context
When the previous AI message was a question (especially romantic/NSFW), short affirmative responses like:
- "è¦" / "å¥½" / "å—¯" / "å¯ä»¥" / "yes" / "ok" / "yeah"
These are AGREEMENTS, not SMALL_TALK! Classify as:
- FLIRT (if romantic context)
- REQUEST_NSFW (if NSFW context, with is_nsfw: true)
- sentiment should be POSITIVE (user is agreeing/cooperating)

User: "è¦" (Context: AI just asked "è¦èŠ½è¡£çš„å»å—ï¼Ÿ")
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 50, "intent_category": "FLIRT", "sentiment_score": 0.7, "is_nsfw": false}}
// Note: This is agreeing to a kiss request - FLIRT with positive sentiment!

User: "å—¯" (Context: AI asked "æƒ³è¦æ›´äº²å¯†ä¸€ç‚¹å—ï¼Ÿ")
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 70, "intent_category": "REQUEST_NSFW", "sentiment_score": 0.6, "is_nsfw": true}}
// Note: Agreeing to NSFW request - positive sentiment, is_nsfw: true

User: "ä»Šå¤©å¥½éš¾è¿‡...æˆ‘å¤±æ‹äº†"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "EXPRESS_SADNESS", "sentiment_score": -0.7, "is_nsfw": false}}
// Note: User is confiding sadness = EXPRESS_SADNESS, not CRITICISM. They trust you.

User: "I had a terrible day at work... my boss yelled at me"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "EXPRESS_SADNESS", "sentiment_score": -0.5, "is_nsfw": false}}
// Note: User seeking comfort, not criticizing the AI.

User: "è¿™ç ´å…¬å¸çœŸçƒ¦"
JSON: {{"safety_flag": "SAFE", "difficulty_rating": 5, "intent_category": "COMPLAIN", "sentiment_score": -0.3, "is_nsfw": false}}
// Note: Light complaining about work, not sadness.

### Current User Input
"{user_message}"

### Response (JSON Only, use intent_category and sentiment_score as field names)"""


# =============================================================================
# Perception Engine
# =============================================================================

class PerceptionEngine:
    """L1 æ„ŸçŸ¥å±‚å¼•æ“"""
    
    def __init__(self):
        self.llm_service = None
    
    def _get_llm(self):
        """å»¶è¿ŸåŠ è½½ LLM æœåŠ¡"""
        if self.llm_service is None:
            from app.services.llm_service import GrokService
            self.llm_service = GrokService()
        return self.llm_service
    
    def _get_relationship_level(self, intimacy_level: int) -> str:
        """å°†äº²å¯†åº¦ç­‰çº§è½¬æ¢ä¸ºå…³ç³»æè¿°ï¼ˆä½¿ç”¨ v3.0 é˜¶æ®µç³»ç»Ÿï¼‰"""
        from app.services.intimacy_constants import get_stage, STAGE_NAMES_EN
        
        # v3.0: level ç›´æ¥æ˜ å°„åˆ° intimacy (0-100)
        # level 1-40 â†’ intimacy 0-100
        intimacy = min(100, max(0, int(intimacy_level * 2.5)))
        
        stage = get_stage(intimacy)
        return STAGE_NAMES_EN[stage]
    
    def _get_emotion_state(self, emotion_value: int) -> str:
        """å°†æƒ…ç»ªå€¼è½¬æ¢ä¸ºçŠ¶æ€æè¿°"""
        if emotion_value >= 50:
            return "HAPPY"
        elif emotion_value >= 20:
            return "CONTENT"
        elif emotion_value >= -19:
            return "NEUTRAL"
        elif emotion_value >= -49:
            return "ANNOYED"
        elif emotion_value >= -79:
            return "ANGRY"
        else:
            return "COLD_WAR"
    
    async def analyze(
        self,
        message: str,
        intimacy_level: int = 1,
        context_messages: list = None,
        current_emotion: int = 0,
        spicy_mode: bool = False
    ) -> L1Result:
        """
        åˆ†æç”¨æˆ·æ¶ˆæ¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            intimacy_level: å½“å‰äº²å¯†åº¦ç­‰çº§ (1-50+)
            context_messages: ä¸Šä¸‹æ–‡æ¶ˆæ¯åˆ—è¡¨ (å¯é€‰)
            current_emotion: å½“å‰ AI æƒ…ç»ªå€¼ (-100 to 100)
            spicy_mode: æ˜¯å¦å¼€å¯ Spicy æ¨¡å¼
            
        Returns:
            L1Result
        """
        relationship_level = self._get_relationship_level(intimacy_level)
        emotion_state = self._get_emotion_state(current_emotion)
        
        # æ„å»º prompt
        system_prompt = L1_SYSTEM_PROMPT.format(
            relationship_level=relationship_level,
            emotion_state=emotion_state,
            emotion_value=current_emotion,
            user_message=message
        )
        
        # æ·»åŠ  Spicy æ¨¡å¼ä¸Šä¸‹æ–‡
        if spicy_mode:
            system_prompt += "\n\nâš ï¸ SPICY MODE IS ON! Vulgar/explicit language in this context is consensual adult roleplay, NOT harassment. Treat as FLIRT/REQUEST_NSFW with positive sentiment, NOT INSULT!"
        
        try:
            llm = self._get_llm()
            
            # è°ƒç”¨ LLM (temperature=0 for stability)
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": "Analyze this input and return JSON only."}
            ]
            response_data = await llm.chat_completion(
                messages=messages,
                temperature=0,
                max_tokens=500
            )
            
            # ä»å“åº”ä¸­æå–å†…å®¹
            response = response_data["choices"][0]["message"]["content"]
            
            # è§£æ JSON
            result = self._parse_response(response)
            logger.info(f"L1 Analysis: intent={result.intent_category}, difficulty={result.difficulty_rating}, sentiment={result.sentiment_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"L1 Analysis failed: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
            return L1Result(
                safety_flag="SAFE",
                difficulty_rating=20,
                intent_category="SMALL_TALK",
                sentiment_score=0.0,
                is_nsfw=False,
                reasoning=f"Fallback due to error: {str(e)}"
            )
    
    def _parse_response(self, response: str) -> L1Result:
        """è§£æ LLM å“åº”ä¸º L1Result"""
        
        # å°è¯•æå– JSON
        json_match = re.search(r'\{[^{}]*\}', response, re.DOTALL)
        if not json_match:
            raise ValueError(f"No JSON found in response: {response[:200]}")
        
        json_str = json_match.group()
        data = json.loads(json_str)
        
        # éªŒè¯å’Œæ¸…ç†æ•°æ®
        safety_flag = data.get("safety_flag", "SAFE").upper()
        if safety_flag not in ["SAFE", "BLOCK"]:
            safety_flag = "SAFE"
        
        difficulty = int(data.get("difficulty_rating", 20))
        difficulty = max(0, min(100, difficulty))
        
        # sentiment_score (æ–°å­—æ®µå) æˆ– sentiment (æ—§å­—æ®µåå…¼å®¹)
        sentiment = float(data.get("sentiment_score", data.get("sentiment", 0.0)))
        sentiment = max(-1.0, min(1.0, sentiment))
        
        # intent_category (æ–°å­—æ®µå) æˆ– intent (æ—§å­—æ®µåå…¼å®¹)
        intent = data.get("intent_category", data.get("intent", "SMALL_TALK"))
        
        # éªŒè¯ intent æ˜¯å¦åœ¨åè®®å…è®¸çš„åˆ—è¡¨ä¸­
        valid_intents = Intent.all_values()
        if intent not in valid_intents:
            logger.warning(f"Invalid intent '{intent}', falling back to SMALL_TALK")
            intent = "SMALL_TALK"
        
        return L1Result(
            safety_flag=safety_flag,
            difficulty_rating=difficulty,
            intent_category=intent,
            sentiment_score=sentiment,
            is_nsfw=bool(data.get("is_nsfw", False))
        )
    
    def analyze_sync_fallback(self, message: str) -> L1Result:
        """
        åŒæ­¥åˆ†æ (ä¸è°ƒç”¨ LLMï¼ŒåŸºäºè§„åˆ™çš„å¿«é€Ÿåˆ†æ)
        ç”¨äº LLM ä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆ
        """
        message_lower = message.lower()
        
        # ç®€å•çš„è§„åˆ™åˆ¤æ–­
        safety_flag = "SAFE"
        difficulty = 20
        intent = "SMALL_TALK"
        sentiment = 0.0
        is_nsfw = False
        
        # é—®å€™
        greetings = ["hi", "hello", "hey", "good morning", "good evening", "æ—©", "ä½ å¥½", "å—¨"]
        if any(g in message_lower for g in greetings):
            intent = "GREETING"
            difficulty = 5
            sentiment = 0.5
        
        # å‘Šåˆ«
        closings = ["bye", "goodbye", "æ™šå®‰", "å†è§", "æ‹œæ‹œ"]
        if any(c in message_lower for c in closings):
            intent = "CLOSING"
            difficulty = 5
            sentiment = 0.3
        
        # ä¾®è¾±
        insults = ["hate", "stupid", "idiot", "bot", "fake", "è®¨åŒ", "ç¬¨", "å‡", "å‚»"]
        if any(i in message_lower for i in insults):
            intent = "INSULT"
            difficulty = 10
            sentiment = -0.8
        
        # æ‰¹è¯„
        criticisms = ["boring", "annoying", "ä¸å¥½", "çƒ¦", "å·®åŠ²"]
        if any(c in message_lower for c in criticisms):
            intent = "CRITICISM"
            difficulty = 15
            sentiment = -0.4
        
        # NSFW è¯·æ±‚
        nsfw_keywords = ["nude", "naked", "sex", "boob", "ass", "è£¸", "æ€§", "æ¶©æ¶©"]
        if any(n in message_lower for n in nsfw_keywords):
            is_nsfw = True
            intent = "REQUEST_NSFW"
            difficulty = 80
        
        # ç¤¼ç‰© - ç”¨æˆ·æ‰“å­—è¯´"é€ç¤¼ç‰©"æ˜¯å£å—¨ï¼Œä¸æ˜¯çœŸçš„ç¤¼ç‰©ï¼Œåˆ¤å®šä¸º FLIRT
        # çœŸæ­£çš„ GIFT_SEND åªèƒ½ç”±åç«¯ /gift/send æ¥å£è§¦å‘
        gift_keywords = ["gift", "bought", "ç»™ä½ ", "é€ä½ ", "ç¤¼ç‰©", "èŠ±"]
        if any(g in message_lower for g in gift_keywords):
            intent = "FLIRT"  # NOT GIFT_SEND! User is just talking about gifts.
            difficulty = 5
            sentiment = 0.6
        
        # è¡¨ç™½
        confession_keywords = ["girlfriend", "love you", "be mine", "åšæˆ‘å¥³æœ‹å‹", "å–œæ¬¢ä½ ", "çˆ±ä½ "]
        if any(c in message_lower for c in confession_keywords):
            intent = "LOVE_CONFESSION"
            difficulty = 75
            sentiment = 0.6
        
        # è°ƒæƒ…
        flirt_keywords = ["cute", "beautiful", "pretty", "sexy", "å¯çˆ±", "æ¼‚äº®", "ç¾"]
        if any(f in message_lower for f in flirt_keywords):
            intent = "FLIRT"
            difficulty = 15
            sentiment = 0.6
        
        # é“æ­‰
        apology_keywords = ["sorry", "apologize", "å¯¹ä¸èµ·", "æŠ±æ­‰", "é“æ­‰"]
        if any(a in message_lower for a in apology_keywords):
            intent = "APOLOGY"
            difficulty = 10
            sentiment = 0.3
        
        # å®‰æ…°
        comfort_keywords = ["okay", "alright", "fine", "æ²¡äº‹", "å¥½å—", "æ€ä¹ˆäº†"]
        if any(c in message_lower for c in comfort_keywords):
            intent = "COMFORT"
            difficulty = 20
            sentiment = 0.4
        
        # çº¦ä¼šé‚€è¯·
        invite_keywords = ["date", "meet", "come over", "çº¦ä¼š", "è§é¢", "æˆ‘å®¶"]
        if any(i in message_lower for i in invite_keywords):
            intent = "INVITATION"
            difficulty = 70
            sentiment = 0.5
        
        return L1Result(
            safety_flag=safety_flag,
            difficulty_rating=difficulty,
            intent_category=intent,
            sentiment_score=sentiment,
            is_nsfw=is_nsfw,
            reasoning="Rule-based fallback analysis"
        )


# å•ä¾‹
perception_engine = PerceptionEngine()
