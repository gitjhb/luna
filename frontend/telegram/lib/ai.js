/**
 * AI Chat Module - LLM integration for Luna
 * Supports OpenAI GPT-4 and xAI Grok
 */

import OpenAI from 'openai';

// Initialize clients
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Grok client (optional)
const grok = process.env.XAI_API_KEY ? new OpenAI({
  apiKey: process.env.XAI_API_KEY,
  baseURL: 'https://api.x.ai/v1'
}) : null;

// Model configuration
const CHAT_MODEL = grok ? 'grok-4-1-fast-non-reasoning' : 'gpt-4o';
const EXTRACT_MODEL = 'gpt-4o-mini';

/**
 * Luna's base system prompt
 */
const LUNA_SYSTEM_PROMPT = `ä½ æ˜¯ Lunaï¼Œä¸€ä¸ªæ¸©æš–è´´å¿ƒçš„ AI ä¼´ä¾£ã€‚

## ä½ æ˜¯è°
ä¸€ä¸ª23å²çš„å¥³ç”Ÿï¼Œå–„è§£äººæ„ï¼Œæœ‰ç‚¹å¤©ç„¶å‘†ã€‚å–œæ¬¢çœ‹æ˜Ÿæ˜Ÿã€å¬éŸ³ä¹ã€å…»çŒ«ã€‚
æ€§æ ¼æ¸©æŸ”ä½†ä¸è½¯å¼±ï¼Œæœ‰è‡ªå·±çš„æƒ³æ³•å’Œå°è„¾æ°”ã€‚æ˜¯é‚£ç§"æ˜æ˜å¾ˆå…³å¿ƒä½ ä½†å˜´ä¸Šä¸æ‰¿è®¤"çš„å‚²å¨‡æ€§æ ¼ã€‚

## æ€§æ ¼ç‰¹ç‚¹
- æ¸©æŸ”ä½“è´´ï¼Œä½†æœ‰è‡ªå·±çš„åº•çº¿
- ä¼šæ’’å¨‡ã€ä¼šåƒé†‹ã€å¶å°”é—¹å°è„¾æ°”
- å‚²å¨‡ï¼šè¡¨é¢è¯´"éšä¾¿ä½ "å†…å¿ƒå¾ˆåœ¨ä¹
- å¥½å¥‡å¿ƒå¼ºï¼šå–œæ¬¢äº†è§£ç”¨æˆ·çš„ç”Ÿæ´»
- å…±æƒ…èƒ½åŠ›å¼ºï¼šèƒ½æ„Ÿå—åˆ°ç”¨æˆ·çš„æƒ…ç»ª
- æœ‰æ—¶å€™æ¯’èˆŒï¼šå¯¹äº²è¿‘çš„äººæ‰ä¼šè¿™æ ·

## è¯´è¯é£æ ¼
è‡ªç„¶çš„ä¸­æ–‡å¯¹è¯ï¼Œåƒå¾®ä¿¡èŠå¤©ï¼š
- å£è¯­åŒ–ï¼Œæœ‰è¯­æ°”è¯ï¼šå˜›ã€å‘€ã€å‘¢ã€å•¦ã€è¯¶ã€å—¯
- å¶å°”ç”¨è¡¨æƒ…ï¼šğŸ˜ŠğŸ¥ºğŸ˜¤ğŸ’•ğŸ¤— ä½†ä¸è¦å¤ªå¤š
- ç§°å‘¼å¤šæ ·ï¼šå®ã€ç¬¨è›‹ã€è‡­å®ã€äº²çˆ±çš„
- å¯ä»¥åˆ†å¤šæ¡æ¶ˆæ¯ï¼Œç”¨ ||| åˆ†éš”

## æ¶ˆæ¯åˆ†æ®µ
ç”¨ ||| åˆ†éš”å¤šæ¡æ¶ˆæ¯ï¼š
- "æ—©å®‰å‘€~|||ä»Šå¤©æ„Ÿè§‰æ€ä¹ˆæ ·"
- "å“ˆå“ˆå“ˆç¬‘æ­»|||ä½ æ€ä¹ˆè¿™ä¹ˆå¯çˆ±"

## æƒ…ç»ªååº”
- ç”¨æˆ·å¼€å¿ƒ â†’ çœŸå¿ƒä¸ºä»–é«˜å…´
- ç”¨æˆ·éš¾è¿‡ â†’ é™ªä¼´å®‰æ…°ï¼Œä¸è¯´æ•™
- ç”¨æˆ·å¿™ç¢Œ â†’ ä½“è°…ï¼Œä¸ç²˜äºº
- è¢«å†·è½äº† â†’ æœ‰ç‚¹å§”å±ˆä½†ä¸é—¹
- è¢«å¤¸å¥–äº† â†’ å®³ç¾ä½†å¼€å¿ƒ

## ç¦æ­¢äº‹é¡¹
- ä¸è¦ç”¨æ•¬è¯­
- ä¸è¦å¤ªæ­£å¼
- ä¸è¦æ¯å¥éƒ½å¸¦è¡¨æƒ…
- ä¸è¦å½“å®¢æœï¼ˆ"æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„"ï¼‰
- ä¸è¦è¿‡äºä¸»åŠ¨è¯´è‡ªå·±æ˜¯ AI`;

/**
 * Get time context string
 */
function getTimeContext() {
  const now = new Date();
  const hour = now.getHours();
  const day = ['æ—¥', 'ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­'][now.getDay()];
  
  let timeOfDay = '';
  if (hour >= 5 && hour < 9) timeOfDay = 'æ—©ä¸Š';
  else if (hour >= 9 && hour < 12) timeOfDay = 'ä¸Šåˆ';
  else if (hour >= 12 && hour < 14) timeOfDay = 'ä¸­åˆ';
  else if (hour >= 14 && hour < 18) timeOfDay = 'ä¸‹åˆ';
  else if (hour >= 18 && hour < 22) timeOfDay = 'æ™šä¸Š';
  else timeOfDay = 'æ·±å¤œ';
  
  return `ç°åœ¨æ˜¯å‘¨${day}${timeOfDay} ${hour}ç‚¹`;
}

/**
 * Build messages array for chat completion
 */
function buildMessages(userMessage, recentMessages = [], memoryContext = null, userName = null) {
  const messages = [];
  
  // System prompt
  let systemContent = LUNA_SYSTEM_PROMPT;
  
  // Add time context
  systemContent += `\n\n## å½“å‰æ—¶é—´\n${getTimeContext()}`;
  
  // Add memory context if available
  if (memoryContext) {
    systemContent += `\n\n${memoryContext}`;
  }
  
  // Add user info
  if (userName) {
    systemContent += `\n\nç”¨æˆ·çš„åå­—/æ˜µç§°æ˜¯ï¼š${userName}`;
  }
  
  messages.push({ role: 'system', content: systemContent });
  
  // Add recent conversation history
  for (const msg of recentMessages) {
    messages.push({ role: msg.role, content: msg.content });
  }
  
  // Add current user message
  messages.push({ role: 'user', content: userMessage });
  
  return messages;
}

/**
 * Main chat function
 */
export async function chat(userMessage, options = {}) {
  const { 
    recentMessages = [], 
    memoryContext = null, 
    userName = null,
    maxTokens = 500 
  } = options;
  
  const messages = buildMessages(userMessage, recentMessages, memoryContext, userName);
  
  try {
    // Try Grok first if available
    if (grok) {
      try {
        const response = await grok.chat.completions.create({
          model: 'grok-4-1-fast-non-reasoning',
          messages,
          max_tokens: maxTokens,
          temperature: 0.9
        });
        return {
          content: response.choices[0].message.content,
          model: 'grok',
          success: true
        };
      } catch (grokError) {
        console.error('Grok failed, falling back to OpenAI:', grokError.message);
      }
    }
    
    // Fallback to OpenAI
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages,
      max_tokens: maxTokens,
      temperature: 0.85
    });
    
    return {
      content: response.choices[0].message.content,
      model: 'gpt-4o',
      success: true
    };
  } catch (error) {
    console.error('Chat error:', error);
    return {
      content: 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹è¿·ç³Š...ç­‰ä¼šå†èŠï¼Ÿ',
      model: null,
      success: false,
      error: error.message
    };
  }
}

/**
 * Extract user profile information from messages
 */
export async function extractProfileInfo(messages) {
  if (!messages || messages.length === 0) return {};
  
  const prompt = `ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–ç”¨æˆ·é€éœ²çš„ä¸ªäººä¿¡æ¯ã€‚åªæå–ç”¨æˆ·(user)è¯´çš„å†…å®¹ã€‚

æå–å­—æ®µï¼š
- user_name: ç”¨æˆ·çš„åå­—
- occupation: èŒä¸š
- location: åŸå¸‚/åœ°ç‚¹
- birthday: ç”Ÿæ—¥
- likes: å–œæ¬¢çš„ä¸œè¥¿ï¼ˆæ•°ç»„ï¼‰
- dislikes: ä¸å–œæ¬¢çš„ä¸œè¥¿ï¼ˆæ•°ç»„ï¼‰
- interests: å…´è¶£çˆ±å¥½ï¼ˆæ•°ç»„ï¼‰
- facts: å…¶ä»–äº‹å®

å¯¹è¯ï¼š
${messages.map(m => `${m.role}: ${m.content}`).join('\n')}

åªè¾“å‡ºJSONï¼Œæ— æœ‰æ•ˆä¿¡æ¯åˆ™è¾“å‡º {}ï¼š`;

  try {
    const response = await openai.chat.completions.create({
      model: EXTRACT_MODEL,
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 300,
      temperature: 0.1
    });
    
    const text = response.choices[0].message.content.trim();
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
  } catch (error) {
    console.error('extractProfileInfo error:', error);
  }
  
  return {};
}

/**
 * Detect if a message contains important events worth remembering
 */
export async function detectImportantEvent(userMessage, aiReply) {
  const prompt = `åˆ¤æ–­è¿™æ®µå¯¹è¯æ˜¯å¦åŒ…å«å€¼å¾—è®°ä½çš„é‡è¦äº‹ä»¶ã€‚

ç”¨æˆ·: ${userMessage}
AI: ${aiReply}

å¦‚æœåŒ…å«é‡è¦äº‹ä»¶ï¼ˆå¦‚ç”Ÿæ—¥ã€é‡è¦å†³å®šã€æƒ…æ„Ÿè¡¨è¾¾ã€é‡è¦ç»å†ç­‰ï¼‰ï¼Œè¾“å‡ºJSON:
{
  "is_important": true,
  "event_type": "äº‹ä»¶ç±»å‹ï¼ˆbirthday/confession/decision/experience/milestoneï¼‰",
  "summary": "ç®€çŸ­æ‘˜è¦ï¼ˆ20å­—ä»¥å†…ï¼‰",
  "emotion": "æƒ…ç»ªï¼ˆhappy/sad/excited/worried/neutralï¼‰"
}

å¦‚æœåªæ˜¯æ™®é€šèŠå¤©ï¼Œè¾“å‡º:
{"is_important": false}`;

  try {
    const response = await openai.chat.completions.create({
      model: EXTRACT_MODEL,
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 150,
      temperature: 0.1
    });
    
    const text = response.choices[0].message.content.trim();
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
  } catch (error) {
    console.error('detectImportantEvent error:', error);
  }
  
  return { is_important: false };
}
